{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence #</th>\n",
       "      <th>Word</th>\n",
       "      <th>POS</th>\n",
       "      <th>Tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1048565</th>\n",
       "      <td>Sentence: 47958</td>\n",
       "      <td>impact</td>\n",
       "      <td>NN</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1048566</th>\n",
       "      <td>Sentence: 47958</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1048567</th>\n",
       "      <td>Sentence: 47959</td>\n",
       "      <td>Indian</td>\n",
       "      <td>JJ</td>\n",
       "      <td>B-gpe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1048568</th>\n",
       "      <td>Sentence: 47959</td>\n",
       "      <td>forces</td>\n",
       "      <td>NNS</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1048569</th>\n",
       "      <td>Sentence: 47959</td>\n",
       "      <td>said</td>\n",
       "      <td>VBD</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1048570</th>\n",
       "      <td>Sentence: 47959</td>\n",
       "      <td>they</td>\n",
       "      <td>PRP</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1048571</th>\n",
       "      <td>Sentence: 47959</td>\n",
       "      <td>responded</td>\n",
       "      <td>VBD</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1048572</th>\n",
       "      <td>Sentence: 47959</td>\n",
       "      <td>to</td>\n",
       "      <td>TO</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1048573</th>\n",
       "      <td>Sentence: 47959</td>\n",
       "      <td>the</td>\n",
       "      <td>DT</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1048574</th>\n",
       "      <td>Sentence: 47959</td>\n",
       "      <td>attack</td>\n",
       "      <td>NN</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Sentence #       Word  POS    Tag\n",
       "1048565  Sentence: 47958     impact   NN      O\n",
       "1048566  Sentence: 47958          .    .      O\n",
       "1048567  Sentence: 47959     Indian   JJ  B-gpe\n",
       "1048568  Sentence: 47959     forces  NNS      O\n",
       "1048569  Sentence: 47959       said  VBD      O\n",
       "1048570  Sentence: 47959       they  PRP      O\n",
       "1048571  Sentence: 47959  responded  VBD      O\n",
       "1048572  Sentence: 47959         to   TO      O\n",
       "1048573  Sentence: 47959        the   DT      O\n",
       "1048574  Sentence: 47959     attack   NN      O"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm, trange\n",
    "\n",
    "data = pd.read_csv(\"dataset kaggle/ner_dataset.csv\", encoding=\"latin1\").fillna(method=\"ffill\")\n",
    "data.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35178"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = list(set(data[\"Word\"].values))\n",
    "n_words = len(words); n_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tags = list(set(data[\"Tag\"].values))\n",
    "n_tags = len(tags); n_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentenceGetter(object):\n",
    "    \n",
    "    def __init__(self, data):\n",
    "        self.n_sent = 1\n",
    "        self.data = data\n",
    "        self.empty = False\n",
    "        agg_func = lambda s: [(w, p, t) for w, p, t in zip(s[\"Word\"].values.tolist(),\n",
    "                                                           s[\"POS\"].values.tolist(),\n",
    "                                                           s[\"Tag\"].values.tolist())]\n",
    "        self.grouped = self.data.groupby(\"Sentence #\").apply(agg_func)\n",
    "        self.sentences = [s for s in self.grouped]\n",
    "    \n",
    "    def get_next(self):\n",
    "        try:\n",
    "            s = self.grouped[\"Sentence: {}\".format(self.n_sent)]\n",
    "            self.n_sent += 1\n",
    "            return s\n",
    "        except:\n",
    "            return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "getter = SentenceGetter(data)\n",
    "sentences = getter.sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Thousands of demonstrators have marched through London to protest the war in Iraq and demand the withdrawal of British troops from that country .'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = [[s[2] for s in sent] for sent in sentences]\n",
    "sentences = [\" \".join([s[0] for s in sent]) for sent in sentences]\n",
    "sentences[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['O', 'O', 'O', 'O', 'O', 'O', 'B-geo', 'O', 'O', 'O', 'O', 'O', 'B-geo', 'O', 'O', 'O', 'O', 'O', 'B-gpe', 'O', 'O', 'O', 'O', 'O']\n"
     ]
    }
   ],
   "source": [
    "print(labels[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "word_cnt = Counter(data[\"Word\"].values)\n",
    "vocabulary = set(w[0] for w in word_cnt.most_common(5000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = 50\n",
    "word2idx = {\"PAD\": 0, \"UNK\": 1}\n",
    "word2idx.update({w: i for i, w in enumerate(words) if w in vocabulary})\n",
    "tag2idx = {t: i for i, t in enumerate(tags)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = [[word2idx.get(w, word2idx[\"UNK\"]) for w in s.split()] for s in sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pad_sequences(maxlen=max_len, sequences=X, padding=\"post\", value=word2idx[\"PAD\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = [[tag2idx[l_i] for l_i in l] for l in labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = pad_sequences(maxlen=max_len, sequences=y, padding=\"post\", value=tag2idx[\"O\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_tr, X_te, y_tr, y_te = train_test_split(X, y, test_size=0.1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras import Input\n",
    "from tensorflow.keras.layers import LSTM, Embedding, Dense, TimeDistributed, SpatialDropout1D, Bidirectional, Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "WARNING:tensorflow:Layer lstm will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "WARNING:tensorflow:Layer lstm will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n"
     ]
    }
   ],
   "source": [
    "word_input = Input(shape=(max_len,))\n",
    "model = Embedding(input_dim=n_words, output_dim=50, input_length=max_len)(word_input)\n",
    "model = SpatialDropout1D(0.1)(model)\n",
    "model = Bidirectional(LSTM(units=100, return_sequences=True, recurrent_dropout=0.1))(model)\n",
    "out = TimeDistributed(Dense(n_tags, activation=\"softmax\"))(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(word_input, out)\n",
    "model.compile(optimizer=\"rmsprop\",\n",
    "              loss=\"sparse_categorical_crossentropy\",\n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1214/1214 [==============================] - 214s 176ms/step - loss: 0.1420 - accuracy: 0.9637 - val_loss: 0.0698 - val_accuracy: 0.9805\n",
      "Epoch 2/5\n",
      "1214/1214 [==============================] - 216s 178ms/step - loss: 0.0647 - accuracy: 0.9810 - val_loss: 0.0608 - val_accuracy: 0.9821\n",
      "Epoch 3/5\n",
      "1214/1214 [==============================] - 243s 200ms/step - loss: 0.0583 - accuracy: 0.9826 - val_loss: 0.0580 - val_accuracy: 0.9829\n",
      "Epoch 4/5\n",
      "1214/1214 [==============================] - 249s 205ms/step - loss: 0.0552 - accuracy: 0.9834 - val_loss: 0.0560 - val_accuracy: 0.9831\n",
      "Epoch 5/5\n",
      "1214/1214 [==============================] - 225s 185ms/step - loss: 0.0532 - accuracy: 0.9839 - val_loss: 0.0561 - val_accuracy: 0.9833\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_tr, y_tr.reshape(*y_tr.shape, 1),\n",
    "                    batch_size=32, epochs=5,\n",
    "                    validation_split=0.1, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rafael/.local/lib/python3.6/site-packages/sklearn/utils/deprecation.py:143: FutureWarning: The sklearn.metrics.scorer module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.metrics. Anything that cannot be imported from sklearn.metrics is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "/home/rafael/.local/lib/python3.6/site-packages/sklearn/utils/deprecation.py:143: FutureWarning: The sklearn.feature_selection.base module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.feature_selection. Anything that cannot be imported from sklearn.feature_selection is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from eli5.lime import TextExplainer\n",
    "from eli5.lime.samplers import MaskingTextSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NERExplainerGenerator(object):\n",
    "    \n",
    "    def __init__(self, model, word2idx, tag2idx, max_len):\n",
    "        self.model = model\n",
    "        self.word2idx = word2idx\n",
    "        self.tag2idx = tag2idx\n",
    "        self.idx2tag = {v: k for k,v in tag2idx.items()}\n",
    "        self.max_len = max_len\n",
    "        \n",
    "    def _preprocess(self, texts):\n",
    "        X = [[self.word2idx.get(w, self.word2idx[\"UNK\"]) for w in t.split()]\n",
    "             for t in texts]\n",
    "        X = pad_sequences(maxlen=self.max_len, sequences=X,\n",
    "                          padding=\"post\", value=self.word2idx[\"PAD\"])\n",
    "        return X\n",
    "    \n",
    "    def get_predict_function(self, word_index):\n",
    "        def predict_func(texts):\n",
    "            X = self._preprocess(texts)\n",
    "            p = self.model.predict(X)\n",
    "            return p[:,word_index,:]\n",
    "        return predict_func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nigeria 's President Olusegun Obasanjo expressed his condolences , noting the late pontiff promoted religious tolerance and democracy in the West African nation .\n",
      "\n",
      "Nigeria (B-geo) 's (O) President (B-per) Olusegun (I-per) Obasanjo (I-per) expressed (O) his (O) condolences (O) , (O) noting (O) the (O) late (O) pontiff (O) promoted (O) religious (O) tolerance (O) and (O) democracy (O) in (O) the (O) West (O) African (B-gpe) nation (O) . (O)\n"
     ]
    }
   ],
   "source": [
    "index = 46781\n",
    "label = labels[index]\n",
    "text = sentences[index]\n",
    "print(text)\n",
    "print()\n",
    "print(\" \".join([f\"{t} ({l})\" for t, l in zip(text.split(), label)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: Nigeria\n",
      "1: 's\n",
      "2: President\n",
      "3: Olusegun\n",
      "4: Obasanjo\n",
      "5: expressed\n",
      "6: his\n",
      "7: condolences\n",
      "8: ,\n",
      "9: noting\n",
      "10: the\n",
      "11: late\n",
      "12: pontiff\n",
      "13: promoted\n",
      "14: religious\n",
      "15: tolerance\n",
      "16: and\n",
      "17: democracy\n",
      "18: in\n",
      "19: the\n",
      "20: West\n",
      "21: African\n",
      "22: nation\n",
      "23: .\n"
     ]
    }
   ],
   "source": [
    "for i, w in enumerate(text.split()):\n",
    "    print(f\"{i}: {w}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer_generator = NERExplainerGenerator(model, word2idx, tag2idx, max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_index = 4\n",
    "predict_func = explainer_generator.get_predict_function(word_index=word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampler = MaskingTextSampler(\n",
    "    replacement=\"UNK\",\n",
    "    max_replace=0.7,\n",
    "    token_pattern=None,\n",
    "    bow=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(\"Nigeria 's President UNK UNK expressed UNK UNK , noting the late pontiff promoted religious UNK and UNK in UNK UNK UNK nation .\", \"UNK 's UNK Olusegun Obasanjo UNK his UNK , UNK the late pontiff promoted UNK tolerance UNK UNK UNK the West African UNK .\", \"Nigeria 'UNK President Olusegun UNK expressed UNK UNK , UNK the late pontiff promoted UNK tolerance UNK democracy in UNK West African UNK .\", \"Nigeria 'UNK President UNK Obasanjo UNK UNK condolences , noting UNK UNK pontiff UNK religious UNK and democracy UNK UNK West African UNK .\")\n"
     ]
    }
   ],
   "source": [
    "samples, similarity = sampler.sample_near(text, n_samples=4)\n",
    "print(samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <style>\n",
       "    table.eli5-weights tr:hover {\n",
       "        filter: brightness(85%);\n",
       "    }\n",
       "</style>\n",
       "\n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "        \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "        \n",
       "    \n",
       "        \n",
       "        \n",
       "    \n",
       "        <p style=\"margin-bottom: 0.5em; margin-top: 0em\">\n",
       "            <b>\n",
       "    \n",
       "        y=I-per\n",
       "    \n",
       "</b>\n",
       "\n",
       "    \n",
       "    (probability <b>0.951</b>, score <b>3.739</b>)\n",
       "\n",
       "top features\n",
       "        </p>\n",
       "    \n",
       "    <table class=\"eli5-weights\"\n",
       "           style=\"border-collapse: collapse; border: none; margin-top: 0em; table-layout: auto; margin-bottom: 2em;\">\n",
       "        <thead>\n",
       "        <tr style=\"border: none;\">\n",
       "            \n",
       "                <th style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\" title=\"Feature contribution already accounts for the feature value (for linear models, contribution = weight * feature value), and the sum of feature contributions is equal to the score or, for some classifiers, to the probability. Feature values are shown if &quot;show_feature_values&quot; is True.\">\n",
       "                    Contribution<sup>?</sup>\n",
       "                </th>\n",
       "            \n",
       "            <th style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">Feature</th>\n",
       "            \n",
       "        </tr>\n",
       "        </thead>\n",
       "        <tbody>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 80.00%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +4.131\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        Highlighted in text (sum)\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "        \n",
       "\n",
       "        \n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 96.16%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -0.391\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        &lt;BIAS&gt;\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "\n",
       "        </tbody>\n",
       "    </table>\n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "\n",
       "    <p style=\"margin-bottom: 2.5em; margin-top:-0.5em;\">\n",
       "        <span style=\"background-color: hsl(0, 100.00%, 92.34%); opacity: 0.82\" title=\"-0.244\">Nigeria</span><span style=\"opacity: 0.80\"> &#x27;</span><span style=\"background-color: hsl(0, 100.00%, 80.24%); opacity: 0.87\" title=\"-0.943\">s</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 63.00%); opacity: 0.98\" title=\"2.312\">President</span><span style=\"opacity: 0.80\"> Olusegun </span><span style=\"background-color: hsl(120, 100.00%, 75.14%); opacity: 0.90\" title=\"1.310\">Obasanjo</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 83.16%); opacity: 0.86\" title=\"0.751\">expressed</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 88.20%); opacity: 0.83\" title=\"0.452\">his</span><span style=\"opacity: 0.80\"> condolences , </span><span style=\"background-color: hsl(120, 100.00%, 97.37%); opacity: 0.80\" title=\"0.053\">noting</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 98.00%); opacity: 0.80\" title=\"0.036\">the</span><span style=\"opacity: 0.80\"> late </span><span style=\"background-color: hsl(120, 100.00%, 99.24%); opacity: 0.80\" title=\"0.009\">pontiff</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 96.88%); opacity: 0.81\" title=\"0.068\">promoted</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 97.13%); opacity: 0.80\" title=\"0.060\">religious</span><span style=\"opacity: 0.80\"> tolerance and democracy </span><span style=\"background-color: hsl(120, 100.00%, 98.23%); opacity: 0.80\" title=\"0.030\">in</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 99.10%); opacity: 0.80\" title=\"0.011\">the</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 93.82%); opacity: 0.81\" title=\"0.179\">West</span><span style=\"opacity: 0.80\"> African nation .</span>\n",
       "    </p>\n",
       "\n",
       "    \n",
       "        \n",
       "    \n",
       "        \n",
       "        \n",
       "    \n",
       "        <p style=\"margin-bottom: 0.5em; margin-top: 0em\">\n",
       "            <b>\n",
       "    \n",
       "        y=I-org\n",
       "    \n",
       "</b>\n",
       "\n",
       "    \n",
       "    (probability <b>0.017</b>, score <b>-4.038</b>)\n",
       "\n",
       "top features\n",
       "        </p>\n",
       "    \n",
       "    <table class=\"eli5-weights\"\n",
       "           style=\"border-collapse: collapse; border: none; margin-top: 0em; table-layout: auto; margin-bottom: 2em;\">\n",
       "        <thead>\n",
       "        <tr style=\"border: none;\">\n",
       "            \n",
       "                <th style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\" title=\"Feature contribution already accounts for the feature value (for linear models, contribution = weight * feature value), and the sum of feature contributions is equal to the score or, for some classifiers, to the probability. Feature values are shown if &quot;show_feature_values&quot; is True.\">\n",
       "                    Contribution<sup>?</sup>\n",
       "                </th>\n",
       "            \n",
       "            <th style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">Feature</th>\n",
       "            \n",
       "        </tr>\n",
       "        </thead>\n",
       "        <tbody>\n",
       "        \n",
       "        \n",
       "\n",
       "        \n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 91.69%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -1.178\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        &lt;BIAS&gt;\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 84.54%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -2.860\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        Highlighted in text (sum)\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "\n",
       "        </tbody>\n",
       "    </table>\n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "\n",
       "    <p style=\"margin-bottom: 2.5em; margin-top:-0.5em;\">\n",
       "        <span style=\"background-color: hsl(120, 100.00%, 94.53%); opacity: 0.81\" title=\"0.151\">Nigeria</span><span style=\"opacity: 0.80\"> &#x27;</span><span style=\"background-color: hsl(120, 100.00%, 82.20%); opacity: 0.86\" title=\"0.813\">s</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 64.27%); opacity: 0.97\" title=\"-2.199\">President</span><span style=\"opacity: 0.80\"> Olusegun </span><span style=\"background-color: hsl(0, 100.00%, 79.44%); opacity: 0.88\" title=\"-0.999\">Obasanjo</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 95.82%); opacity: 0.81\" title=\"-0.102\">expressed</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 92.31%); opacity: 0.82\" title=\"-0.245\">his</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 94.04%); opacity: 0.81\" title=\"-0.170\">condolences</span><span style=\"opacity: 0.80\"> , </span><span style=\"background-color: hsl(0, 100.00%, 99.00%); opacity: 0.80\" title=\"-0.013\">noting</span><span style=\"opacity: 0.80\"> the late pontiff </span><span style=\"background-color: hsl(0, 100.00%, 99.31%); opacity: 0.80\" title=\"-0.008\">promoted</span><span style=\"opacity: 0.80\"> religious tolerance and democracy </span><span style=\"background-color: hsl(0, 100.00%, 99.32%); opacity: 0.80\" title=\"-0.008\">in</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 98.37%); opacity: 0.80\" title=\"-0.027\">the</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 97.38%); opacity: 0.80\" title=\"-0.053\">West</span><span style=\"opacity: 0.80\"> African nation .</span>\n",
       "    </p>\n",
       "\n",
       "    \n",
       "        \n",
       "    \n",
       "        \n",
       "        \n",
       "    \n",
       "        <p style=\"margin-bottom: 0.5em; margin-top: 0em\">\n",
       "            <b>\n",
       "    \n",
       "        y=I-geo\n",
       "    \n",
       "</b>\n",
       "\n",
       "    \n",
       "    (probability <b>0.013</b>, score <b>-4.328</b>)\n",
       "\n",
       "top features\n",
       "        </p>\n",
       "    \n",
       "    <table class=\"eli5-weights\"\n",
       "           style=\"border-collapse: collapse; border: none; margin-top: 0em; table-layout: auto; margin-bottom: 2em;\">\n",
       "        <thead>\n",
       "        <tr style=\"border: none;\">\n",
       "            \n",
       "                <th style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\" title=\"Feature contribution already accounts for the feature value (for linear models, contribution = weight * feature value), and the sum of feature contributions is equal to the score or, for some classifiers, to the probability. Feature values are shown if &quot;show_feature_values&quot; is True.\">\n",
       "                    Contribution<sup>?</sup>\n",
       "                </th>\n",
       "            \n",
       "            <th style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">Feature</th>\n",
       "            \n",
       "        </tr>\n",
       "        </thead>\n",
       "        <tbody>\n",
       "        \n",
       "        \n",
       "\n",
       "        \n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 96.67%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -0.319\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        Highlighted in text (sum)\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 80.42%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -4.008\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        &lt;BIAS&gt;\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "\n",
       "        </tbody>\n",
       "    </table>\n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "\n",
       "    <p style=\"margin-bottom: 2.5em; margin-top:-0.5em;\">\n",
       "        <span style=\"background-color: hsl(120, 100.00%, 82.26%); opacity: 0.86\" title=\"0.809\">Nigeria</span><span style=\"opacity: 0.80\"> &#x27;</span><span style=\"background-color: hsl(120, 100.00%, 79.88%); opacity: 0.87\" title=\"0.968\">s</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 60.00%); opacity: 1.00\" title=\"-2.584\">President</span><span style=\"opacity: 0.80\"> Olusegun </span><span style=\"background-color: hsl(120, 100.00%, 87.37%); opacity: 0.84\" title=\"0.498\">Obasanjo</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 92.09%); opacity: 0.82\" title=\"0.255\">expressed</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 96.50%); opacity: 0.81\" title=\"-0.080\">his</span><span style=\"opacity: 0.80\"> condolences , </span><span style=\"background-color: hsl(0, 100.00%, 96.94%); opacity: 0.81\" title=\"-0.066\">noting</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 99.20%); opacity: 0.80\" title=\"-0.010\">the</span><span style=\"opacity: 0.80\"> late pontiff promoted </span><span style=\"background-color: hsl(0, 100.00%, 98.85%); opacity: 0.80\" title=\"-0.016\">religious</span><span style=\"opacity: 0.80\"> tolerance and democracy in the West African </span><span style=\"background-color: hsl(0, 100.00%, 96.09%); opacity: 0.81\" title=\"-0.093\">nation</span><span style=\"opacity: 0.80\"> .</span>\n",
       "    </p>\n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "Explanation(estimator=\"SGDClassifier(alpha=0.001, loss='log', penalty='elasticnet',\\n              random_state=RandomState(MT19937) at 0x7FF1BC198780)\", description=None, error=None, method='linear model', is_regression=False, targets=[TargetExplanation(target='I-per', feature_weights=FeatureWeights(pos=[FeatureWeight(feature='[2] President', weight=2.3115553579036816, std=None, value=1.0), FeatureWeight(feature='[4] Obasanjo', weight=1.309743203410542, std=None, value=1.0), FeatureWeight(feature='[5] expressed', weight=0.751053573116149, std=None, value=1.0), FeatureWeight(feature='[6] his', weight=0.4519616038402774, std=None, value=1.0), FeatureWeight(feature='[19] West', weight=0.17944982727660921, std=None, value=1.0), FeatureWeight(feature='[9] the', weight=0.0715406839686392, std=None, value=1.0), FeatureWeight(feature='[12] promoted', weight=0.06753566617733808, std=None, value=1.0), FeatureWeight(feature='[13] religious', weight=0.059833197339650326, std=None, value=1.0), FeatureWeight(feature='[8] noting', weight=0.05296511979492629, std=None, value=1.0), FeatureWeight(feature='[17] in', weight=0.030108022259374714, std=None, value=1.0), FeatureWeight(feature='[18] the', weight=0.0228368023242326, std=None, value=1.0), FeatureWeight(feature='[11] pontiff', weight=0.008934764671909458, std=None, value=1.0)], neg=[FeatureWeight(feature='[1] s', weight=-0.9433853722092158, std=None, value=1.0), FeatureWeight(feature='<BIAS>', weight=-0.39122225819624806, std=None, value=1.0), FeatureWeight(feature='[0] Nigeria', weight=-0.24358719851971386, std=None, value=1.0)], pos_remaining=0, neg_remaining=0), proba=0.9510723020832127, score=3.739322993158152, weighted_spans=WeightedSpans(docs_weighted_spans=[DocWeightedSpans(document=\"Nigeria 's President Olusegun Obasanjo expressed his condolences , noting the late pontiff promoted religious tolerance and democracy in the West African nation .\", spans=[('Nigeria', [(0, 7)], -0.24358719851971386), ('s', [(9, 10)], -0.9433853722092158), ('President', [(11, 20)], 2.3115553579036816), ('Obasanjo', [(30, 38)], 1.309743203410542), ('expressed', [(39, 48)], 0.751053573116149), ('his', [(49, 52)], 0.4519616038402774), ('noting', [(67, 73)], 0.05296511979492629), ('the', [(74, 77)], 0.0715406839686392), ('pontiff', [(83, 90)], 0.008934764671909458), ('promoted', [(91, 99)], 0.06753566617733808), ('religious', [(100, 109)], 0.059833197339650326), ('in', [(134, 136)], 0.030108022259374714), ('the', [(137, 140)], 0.0228368023242326), ('West', [(141, 145)], 0.17944982727660921)], preserve_density=False, vec_name=None)], other=FeatureWeights(pos=[FeatureWeight(feature=<FormattedFeatureName 'Highlighted in text (sum)'>, weight=4.1305452513544, std=None, value=None)], neg=[FeatureWeight(feature='<BIAS>', weight=-0.39122225819624806, std=None, value=1.0)], pos_remaining=0, neg_remaining=0)), heatmap=None), TargetExplanation(target='I-org', feature_weights=FeatureWeights(pos=[FeatureWeight(feature='[1] s', weight=0.8128720419436449, std=None, value=1.0), FeatureWeight(feature='[0] Nigeria', weight=0.15063541687242368, std=None, value=1.0)], neg=[FeatureWeight(feature='[2] President', weight=-2.1989923699490044, std=None, value=1.0), FeatureWeight(feature='<BIAS>', weight=-1.1779570286008907, std=None, value=1.0), FeatureWeight(feature='[4] Obasanjo', weight=-0.9985150017205143, std=None, value=1.0), FeatureWeight(feature='[6] his', weight=-0.2449468106620426, std=None, value=1.0), FeatureWeight(feature='[7] condolences', weight=-0.1704275403843261, std=None, value=1.0), FeatureWeight(feature='[5] expressed', weight=-0.10247208111895438, std=None, value=1.0), FeatureWeight(feature='[19] West', weight=-0.0526786120561627, std=None, value=1.0), FeatureWeight(feature='[18] the', weight=-0.026629654149700466, std=None, value=1.0), FeatureWeight(feature='[8] noting', weight=-0.01330843279501636, std=None, value=1.0), FeatureWeight(feature='[12] promoted', weight=-0.007848049450069552, std=None, value=1.0), FeatureWeight(feature='[17] in', weight=-0.007642633533731664, std=None, value=1.0)], pos_remaining=0, neg_remaining=0), proba=0.01687259676792439, score=-4.0379107556043445, weighted_spans=WeightedSpans(docs_weighted_spans=[DocWeightedSpans(document=\"Nigeria 's President Olusegun Obasanjo expressed his condolences , noting the late pontiff promoted religious tolerance and democracy in the West African nation .\", spans=[('Nigeria', [(0, 7)], 0.15063541687242368), ('s', [(9, 10)], 0.8128720419436449), ('President', [(11, 20)], -2.1989923699490044), ('Obasanjo', [(30, 38)], -0.9985150017205143), ('expressed', [(39, 48)], -0.10247208111895438), ('his', [(49, 52)], -0.2449468106620426), ('condolences', [(53, 64)], -0.1704275403843261), ('noting', [(67, 73)], -0.01330843279501636), ('promoted', [(91, 99)], -0.007848049450069552), ('in', [(134, 136)], -0.007642633533731664), ('the', [(137, 140)], -0.026629654149700466), ('West', [(141, 145)], -0.0526786120561627)], preserve_density=False, vec_name=None)], other=FeatureWeights(pos=[], neg=[FeatureWeight(feature=<FormattedFeatureName 'Highlighted in text (sum)'>, weight=-2.859953727003454, std=None, value=None), FeatureWeight(feature='<BIAS>', weight=-1.1779570286008907, std=None, value=1.0)], pos_remaining=0, neg_remaining=0)), heatmap=None), TargetExplanation(target='I-geo', feature_weights=FeatureWeights(pos=[FeatureWeight(feature='[1] s', weight=0.9679687740378039, std=None, value=1.0), FeatureWeight(feature='[0] Nigeria', weight=0.8086812887740098, std=None, value=1.0), FeatureWeight(feature='[4] Obasanjo', weight=0.49792667396180645, std=None, value=1.0), FeatureWeight(feature='[5] expressed', weight=0.2550124166877276, std=None, value=1.0)], neg=[FeatureWeight(feature='<BIAS>', weight=-4.008479031142097, std=None, value=1.0), FeatureWeight(feature='[2] President', weight=-2.584239389205146, std=None, value=1.0), FeatureWeight(feature='[21] nation', weight=-0.09309090297903051, std=None, value=1.0), FeatureWeight(feature='[6] his', weight=-0.07963701919156642, std=None, value=1.0), FeatureWeight(feature='[8] noting', weight=-0.06583011019476019, std=None, value=1.0), FeatureWeight(feature='[13] religious', weight=-0.016190994676866813, std=None, value=1.0), FeatureWeight(feature='[9] the', weight=-0.009747852033101545, std=None, value=1.0)], pos_remaining=0, neg_remaining=0), proba=0.01268402746884005, score=-4.327626145961221, weighted_spans=WeightedSpans(docs_weighted_spans=[DocWeightedSpans(document=\"Nigeria 's President Olusegun Obasanjo expressed his condolences , noting the late pontiff promoted religious tolerance and democracy in the West African nation .\", spans=[('Nigeria', [(0, 7)], 0.8086812887740098), ('s', [(9, 10)], 0.9679687740378039), ('President', [(11, 20)], -2.584239389205146), ('Obasanjo', [(30, 38)], 0.49792667396180645), ('expressed', [(39, 48)], 0.2550124166877276), ('his', [(49, 52)], -0.07963701919156642), ('noting', [(67, 73)], -0.06583011019476019), ('the', [(74, 77)], -0.009747852033101545), ('religious', [(100, 109)], -0.016190994676866813), ('nation', [(154, 160)], -0.09309090297903051)], preserve_density=False, vec_name=None)], other=FeatureWeights(pos=[], neg=[FeatureWeight(feature='<BIAS>', weight=-4.008479031142097, std=None, value=1.0), FeatureWeight(feature=<FormattedFeatureName 'Highlighted in text (sum)'>, weight=-0.3191471148191239, std=None, value=None)], pos_remaining=0, neg_remaining=0)), heatmap=None)], feature_importances=None, decision_tree=None, highlight_spaces=None, transition_features=None, image=None)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "te = TextExplainer(\n",
    "    sampler=sampler,\n",
    "    position_dependent=True,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "te.fit(text, predict_func)\n",
    "\n",
    "te.explain_prediction(\n",
    "    target_names=list(explainer_generator.idx2tag.values()),\n",
    "    top_targets=3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model.predict(X_te)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The\n"
     ]
    }
   ],
   "source": [
    "tags[np.argmax(preds[0][0])], X_te,\n",
    "word2idx\n",
    "search_number = 3505\n",
    "for name, age in word2idx.items():\n",
    "    if age == search_number:\n",
    "        print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('ModeloTestInicialExemploInternet.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "WARNING:tensorflow:Layer lstm will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "WARNING:tensorflow:Layer lstm will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "model_load = tf.keras.models.load_model('ModeloTestInicialExemploInternet.h5') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model was constructed with shape (None, 50) for input Tensor(\"input_2_1:0\", shape=(None, 50), dtype=float32), but it was called on an input with incompatible shape (None, 1).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[[1.15639505e-05, 1.13679875e-04, 4.71319845e-06, 2.77629556e-06,\n",
       "         1.15233520e-03, 5.08128178e-05, 2.07925332e-05, 9.81708581e-05,\n",
       "         2.84267444e-05, 1.21134457e-04, 2.90967035e-03, 1.06746134e-04,\n",
       "         5.29559693e-05, 2.60413032e-07, 2.27524160e-05, 9.94926572e-01,\n",
       "         3.76516691e-04]],\n",
       "\n",
       "       [[2.50009180e-05, 3.69176298e-04, 1.61493681e-05, 6.19811863e-06,\n",
       "         6.04283880e-04, 4.33768328e-05, 6.59549478e-05, 9.02706015e-05,\n",
       "         2.06063996e-05, 6.09474140e-04, 4.76114277e-04, 4.72351239e-04,\n",
       "         5.60766493e-05, 1.30801925e-06, 4.74560329e-05, 9.96962965e-01,\n",
       "         1.33247391e-04]],\n",
       "\n",
       "       [[7.11442726e-06, 2.25686748e-03, 1.98420676e-05, 4.63881133e-06,\n",
       "         4.05521365e-04, 2.55815357e-05, 3.24534689e-04, 3.56102741e-04,\n",
       "         4.21336199e-06, 1.15333882e-04, 7.61578325e-04, 7.48601960e-05,\n",
       "         3.75192067e-05, 6.52009362e-07, 2.03205145e-05, 9.95456696e-01,\n",
       "         1.28622793e-04]],\n",
       "\n",
       "       [[2.08730100e-07, 2.04193184e-05, 1.20678877e-07, 7.03770056e-08,\n",
       "         5.86270180e-05, 1.91516574e-06, 1.64125549e-06, 4.05106312e-06,\n",
       "         3.09333302e-07, 2.11858842e-05, 4.58596842e-05, 1.70949861e-05,\n",
       "         1.91171512e-06, 6.80680845e-09, 1.01116837e-06, 9.99799073e-01,\n",
       "         2.66061470e-05]],\n",
       "\n",
       "       [[2.29283492e-03, 2.24354059e-01, 1.95040251e-03, 1.98265817e-03,\n",
       "         1.22116329e-02, 1.57968309e-02, 6.62707627e-01, 1.76163651e-02,\n",
       "         3.28221096e-04, 1.32560628e-02, 8.17339402e-03, 4.69217589e-03,\n",
       "         1.08792866e-03, 9.56820732e-04, 3.67237371e-03, 1.80577803e-02,\n",
       "         1.08629158e-02]],\n",
       "\n",
       "       [[3.28564988e-06, 1.71032589e-04, 5.86819340e-07, 9.84341227e-07,\n",
       "         1.91836897e-03, 7.40230389e-05, 6.80196026e-05, 1.29307873e-05,\n",
       "         2.27566011e-06, 1.27844367e-04, 6.85046602e-04, 9.20744133e-05,\n",
       "         1.57399863e-05, 1.05362915e-07, 2.25427702e-05, 9.96631563e-01,\n",
       "         1.73611668e-04]],\n",
       "\n",
       "       [[1.61765329e-05, 2.87682517e-04, 8.91239142e-06, 4.25167582e-06,\n",
       "         5.88102092e-04, 3.81980353e-05, 5.42194175e-05, 9.13268814e-05,\n",
       "         1.35773271e-05, 2.60052737e-04, 5.19439986e-04, 4.18040232e-04,\n",
       "         4.16531002e-05, 8.40593543e-07, 3.14947647e-05, 9.97461796e-01,\n",
       "         1.64320692e-04]],\n",
       "\n",
       "       [[2.50950507e-05, 6.28635229e-04, 2.10177914e-05, 7.57082944e-06,\n",
       "         1.07761333e-03, 4.87602010e-05, 1.03517334e-04, 2.82015797e-04,\n",
       "         1.95737412e-05, 2.49856705e-04, 1.13701273e-03, 2.40212888e-04,\n",
       "         6.95322015e-05, 1.26319901e-06, 4.87888501e-05, 9.95875657e-01,\n",
       "         1.63968347e-04]],\n",
       "\n",
       "       [[1.71179068e-04, 1.83370858e-02, 1.14954659e-04, 1.00195222e-03,\n",
       "         3.13607827e-02, 1.49153480e-02, 5.07738302e-03, 6.15764000e-02,\n",
       "         1.26991607e-03, 4.76568844e-03, 3.13708633e-01, 1.76001783e-03,\n",
       "         3.57334572e-03, 3.24547691e-05, 1.12710125e-03, 1.04086250e-02,\n",
       "         5.30799091e-01]],\n",
       "\n",
       "       [[5.06468405e-06, 1.37107229e-04, 1.80326322e-06, 5.49134029e-07,\n",
       "         4.43682715e-04, 1.26132318e-05, 3.40260522e-05, 1.45246377e-05,\n",
       "         4.10547409e-06, 3.29646537e-05, 2.27748067e-04, 1.49141211e-04,\n",
       "         1.27568628e-05, 2.08585277e-07, 1.19092801e-05, 9.98834789e-01,\n",
       "         7.69554390e-05]],\n",
       "\n",
       "       [[4.51134425e-03, 3.92194577e-02, 1.40453316e-03, 6.64515654e-03,\n",
       "         1.42576098e-01, 5.23025431e-02, 1.66140776e-02, 7.14312270e-02,\n",
       "         1.24972211e-02, 1.66388433e-02, 3.62467855e-01, 6.08522911e-03,\n",
       "         1.61383823e-02, 5.77069353e-04, 7.57961161e-03, 2.63402350e-02,\n",
       "         2.16971070e-01]],\n",
       "\n",
       "       [[5.06468405e-06, 1.37107229e-04, 1.80326322e-06, 5.49134029e-07,\n",
       "         4.43682715e-04, 1.26132318e-05, 3.40260522e-05, 1.45246377e-05,\n",
       "         4.10547409e-06, 3.29646537e-05, 2.27748067e-04, 1.49141211e-04,\n",
       "         1.27568628e-05, 2.08585277e-07, 1.19092801e-05, 9.98834789e-01,\n",
       "         7.69554390e-05]],\n",
       "\n",
       "       [[1.08650897e-03, 6.26450926e-02, 5.03801159e-04, 3.60342953e-03,\n",
       "         7.14991763e-02, 5.57838753e-02, 3.60395871e-02, 1.01849206e-01,\n",
       "         3.23829637e-03, 1.56339742e-02, 1.52873591e-01, 7.75372935e-03,\n",
       "         7.05807330e-03, 2.94048659e-04, 4.59891465e-03, 8.31927452e-03,\n",
       "         4.67219472e-01]],\n",
       "\n",
       "       [[5.06468405e-06, 1.37107229e-04, 1.80326322e-06, 5.49134029e-07,\n",
       "         4.43682715e-04, 1.26132318e-05, 3.40260522e-05, 1.45246377e-05,\n",
       "         4.10547409e-06, 3.29646537e-05, 2.27748067e-04, 1.49141211e-04,\n",
       "         1.27568628e-05, 2.08585277e-07, 1.19092801e-05, 9.98834789e-01,\n",
       "         7.69554390e-05]],\n",
       "\n",
       "       [[2.84524140e-05, 3.08161165e-04, 6.82028713e-06, 2.16730814e-06,\n",
       "         3.57360928e-03, 4.70491250e-05, 9.84422077e-05, 5.55047591e-05,\n",
       "         1.36900517e-05, 7.15318165e-05, 5.07190591e-04, 3.01706343e-04,\n",
       "         3.23836684e-05, 6.13066447e-07, 4.37807612e-05, 9.94842470e-01,\n",
       "         6.65049811e-05]],\n",
       "\n",
       "       [[3.67969507e-04, 2.65759304e-02, 2.08746351e-04, 1.51653669e-03,\n",
       "         4.42183651e-02, 2.57019885e-02, 7.61051802e-03, 6.96642697e-02,\n",
       "         2.06861715e-03, 1.13496874e-02, 2.41759047e-01, 3.63707356e-03,\n",
       "         5.20507991e-03, 7.40426913e-05, 1.99747970e-03, 1.40406573e-02,\n",
       "         5.44004023e-01]],\n",
       "\n",
       "       [[1.46187460e-07, 2.92608979e-06, 2.95676372e-08, 3.23226104e-08,\n",
       "         1.79870785e-05, 7.27911356e-07, 3.46156924e-07, 3.39342193e-07,\n",
       "         1.41334269e-07, 4.67493992e-05, 8.07638844e-06, 2.58158179e-05,\n",
       "         5.80407402e-07, 3.82176157e-09, 5.97962412e-07, 9.99889970e-01,\n",
       "         5.44532213e-06]],\n",
       "\n",
       "       [[1.04876665e-06, 1.64558747e-04, 5.59524665e-07, 2.47252132e-07,\n",
       "         2.56142608e-04, 8.14913437e-06, 2.03822328e-05, 6.26300152e-06,\n",
       "         5.90053446e-07, 3.92889451e-05, 9.10571107e-05, 3.64288026e-05,\n",
       "         4.84024895e-06, 3.58280765e-08, 5.31472142e-06, 9.99345124e-01,\n",
       "         1.98931666e-05]],\n",
       "\n",
       "       [[1.04876665e-06, 1.64558747e-04, 5.59524665e-07, 2.47252132e-07,\n",
       "         2.56142608e-04, 8.14913437e-06, 2.03822328e-05, 6.26300152e-06,\n",
       "         5.90053446e-07, 3.92889451e-05, 9.10571107e-05, 3.64288026e-05,\n",
       "         4.84024895e-06, 3.58280765e-08, 5.31472142e-06, 9.99345124e-01,\n",
       "         1.98931666e-05]],\n",
       "\n",
       "       [[1.04876665e-06, 1.64558747e-04, 5.59524665e-07, 2.47252132e-07,\n",
       "         2.56142608e-04, 8.14913437e-06, 2.03822328e-05, 6.26300152e-06,\n",
       "         5.90053446e-07, 3.92889451e-05, 9.10571107e-05, 3.64288026e-05,\n",
       "         4.84024895e-06, 3.58280765e-08, 5.31472142e-06, 9.99345124e-01,\n",
       "         1.98931666e-05]],\n",
       "\n",
       "       [[1.04876665e-06, 1.64558747e-04, 5.59524665e-07, 2.47252132e-07,\n",
       "         2.56142608e-04, 8.14913437e-06, 2.03822328e-05, 6.26300152e-06,\n",
       "         5.90053446e-07, 3.92889451e-05, 9.10571107e-05, 3.64288026e-05,\n",
       "         4.84024895e-06, 3.58280765e-08, 5.31472142e-06, 9.99345124e-01,\n",
       "         1.98931666e-05]],\n",
       "\n",
       "       [[1.04876665e-06, 1.64558747e-04, 5.59524665e-07, 2.47252132e-07,\n",
       "         2.56142608e-04, 8.14913437e-06, 2.03822328e-05, 6.26300152e-06,\n",
       "         5.90053446e-07, 3.92889451e-05, 9.10571107e-05, 3.64288026e-05,\n",
       "         4.84024895e-06, 3.58280765e-08, 5.31472142e-06, 9.99345124e-01,\n",
       "         1.98931666e-05]],\n",
       "\n",
       "       [[1.04876665e-06, 1.64558747e-04, 5.59524665e-07, 2.47252132e-07,\n",
       "         2.56142608e-04, 8.14913437e-06, 2.03822328e-05, 6.26300152e-06,\n",
       "         5.90053446e-07, 3.92889451e-05, 9.10571107e-05, 3.64288026e-05,\n",
       "         4.84024895e-06, 3.58280765e-08, 5.31472142e-06, 9.99345124e-01,\n",
       "         1.98931666e-05]],\n",
       "\n",
       "       [[1.04876665e-06, 1.64558747e-04, 5.59524665e-07, 2.47252132e-07,\n",
       "         2.56142608e-04, 8.14913437e-06, 2.03822328e-05, 6.26300152e-06,\n",
       "         5.90053446e-07, 3.92889451e-05, 9.10571107e-05, 3.64288026e-05,\n",
       "         4.84024895e-06, 3.58280765e-08, 5.31472142e-06, 9.99345124e-01,\n",
       "         1.98931666e-05]],\n",
       "\n",
       "       [[1.04876665e-06, 1.64558747e-04, 5.59524665e-07, 2.47252132e-07,\n",
       "         2.56142608e-04, 8.14913437e-06, 2.03822328e-05, 6.26300152e-06,\n",
       "         5.90053446e-07, 3.92889451e-05, 9.10571107e-05, 3.64288026e-05,\n",
       "         4.84024895e-06, 3.58280765e-08, 5.31472142e-06, 9.99345124e-01,\n",
       "         1.98931666e-05]],\n",
       "\n",
       "       [[1.04876665e-06, 1.64558747e-04, 5.59524665e-07, 2.47252132e-07,\n",
       "         2.56142608e-04, 8.14913437e-06, 2.03822328e-05, 6.26300152e-06,\n",
       "         5.90053446e-07, 3.92889451e-05, 9.10571107e-05, 3.64288026e-05,\n",
       "         4.84024895e-06, 3.58280765e-08, 5.31472142e-06, 9.99345124e-01,\n",
       "         1.98931666e-05]],\n",
       "\n",
       "       [[1.04876665e-06, 1.64558747e-04, 5.59524665e-07, 2.47252132e-07,\n",
       "         2.56142608e-04, 8.14913437e-06, 2.03822328e-05, 6.26300152e-06,\n",
       "         5.90053446e-07, 3.92889451e-05, 9.10571107e-05, 3.64288026e-05,\n",
       "         4.84024895e-06, 3.58280765e-08, 5.31472142e-06, 9.99345124e-01,\n",
       "         1.98931666e-05]],\n",
       "\n",
       "       [[1.04876665e-06, 1.64558747e-04, 5.59524665e-07, 2.47252132e-07,\n",
       "         2.56142608e-04, 8.14913437e-06, 2.03822328e-05, 6.26300152e-06,\n",
       "         5.90053446e-07, 3.92889451e-05, 9.10571107e-05, 3.64288026e-05,\n",
       "         4.84024895e-06, 3.58280765e-08, 5.31472142e-06, 9.99345124e-01,\n",
       "         1.98931666e-05]],\n",
       "\n",
       "       [[1.04876665e-06, 1.64558747e-04, 5.59524665e-07, 2.47252132e-07,\n",
       "         2.56142608e-04, 8.14913437e-06, 2.03822328e-05, 6.26300152e-06,\n",
       "         5.90053446e-07, 3.92889451e-05, 9.10571107e-05, 3.64288026e-05,\n",
       "         4.84024895e-06, 3.58280765e-08, 5.31472142e-06, 9.99345124e-01,\n",
       "         1.98931666e-05]],\n",
       "\n",
       "       [[1.04876665e-06, 1.64558747e-04, 5.59524665e-07, 2.47252132e-07,\n",
       "         2.56142608e-04, 8.14913437e-06, 2.03822328e-05, 6.26300152e-06,\n",
       "         5.90053446e-07, 3.92889451e-05, 9.10571107e-05, 3.64288026e-05,\n",
       "         4.84024895e-06, 3.58280765e-08, 5.31472142e-06, 9.99345124e-01,\n",
       "         1.98931666e-05]],\n",
       "\n",
       "       [[1.04876665e-06, 1.64558747e-04, 5.59524665e-07, 2.47252132e-07,\n",
       "         2.56142608e-04, 8.14913437e-06, 2.03822328e-05, 6.26300152e-06,\n",
       "         5.90053446e-07, 3.92889451e-05, 9.10571107e-05, 3.64288026e-05,\n",
       "         4.84024895e-06, 3.58280765e-08, 5.31472142e-06, 9.99345124e-01,\n",
       "         1.98931666e-05]],\n",
       "\n",
       "       [[1.04876665e-06, 1.64558747e-04, 5.59524665e-07, 2.47252132e-07,\n",
       "         2.56142608e-04, 8.14913437e-06, 2.03822328e-05, 6.26300152e-06,\n",
       "         5.90053446e-07, 3.92889451e-05, 9.10571107e-05, 3.64288026e-05,\n",
       "         4.84024895e-06, 3.58280765e-08, 5.31472142e-06, 9.99345124e-01,\n",
       "         1.98931666e-05]],\n",
       "\n",
       "       [[1.04876665e-06, 1.64558747e-04, 5.59524665e-07, 2.47252132e-07,\n",
       "         2.56142608e-04, 8.14913437e-06, 2.03822328e-05, 6.26300152e-06,\n",
       "         5.90053446e-07, 3.92889451e-05, 9.10571107e-05, 3.64288026e-05,\n",
       "         4.84024895e-06, 3.58280765e-08, 5.31472142e-06, 9.99345124e-01,\n",
       "         1.98931666e-05]],\n",
       "\n",
       "       [[1.04876665e-06, 1.64558747e-04, 5.59524665e-07, 2.47252132e-07,\n",
       "         2.56142608e-04, 8.14913437e-06, 2.03822328e-05, 6.26300152e-06,\n",
       "         5.90053446e-07, 3.92889451e-05, 9.10571107e-05, 3.64288026e-05,\n",
       "         4.84024895e-06, 3.58280765e-08, 5.31472142e-06, 9.99345124e-01,\n",
       "         1.98931666e-05]],\n",
       "\n",
       "       [[1.04876665e-06, 1.64558747e-04, 5.59524665e-07, 2.47252132e-07,\n",
       "         2.56142608e-04, 8.14913437e-06, 2.03822328e-05, 6.26300152e-06,\n",
       "         5.90053446e-07, 3.92889451e-05, 9.10571107e-05, 3.64288026e-05,\n",
       "         4.84024895e-06, 3.58280765e-08, 5.31472142e-06, 9.99345124e-01,\n",
       "         1.98931666e-05]],\n",
       "\n",
       "       [[1.04876665e-06, 1.64558747e-04, 5.59524665e-07, 2.47252132e-07,\n",
       "         2.56142608e-04, 8.14913437e-06, 2.03822328e-05, 6.26300152e-06,\n",
       "         5.90053446e-07, 3.92889451e-05, 9.10571107e-05, 3.64288026e-05,\n",
       "         4.84024895e-06, 3.58280765e-08, 5.31472142e-06, 9.99345124e-01,\n",
       "         1.98931666e-05]],\n",
       "\n",
       "       [[1.04876665e-06, 1.64558747e-04, 5.59524665e-07, 2.47252132e-07,\n",
       "         2.56142608e-04, 8.14913437e-06, 2.03822328e-05, 6.26300152e-06,\n",
       "         5.90053446e-07, 3.92889451e-05, 9.10571107e-05, 3.64288026e-05,\n",
       "         4.84024895e-06, 3.58280765e-08, 5.31472142e-06, 9.99345124e-01,\n",
       "         1.98931666e-05]],\n",
       "\n",
       "       [[1.04876665e-06, 1.64558747e-04, 5.59524665e-07, 2.47252132e-07,\n",
       "         2.56142608e-04, 8.14913437e-06, 2.03822328e-05, 6.26300152e-06,\n",
       "         5.90053446e-07, 3.92889451e-05, 9.10571107e-05, 3.64288026e-05,\n",
       "         4.84024895e-06, 3.58280765e-08, 5.31472142e-06, 9.99345124e-01,\n",
       "         1.98931666e-05]],\n",
       "\n",
       "       [[1.04876665e-06, 1.64558747e-04, 5.59524665e-07, 2.47252132e-07,\n",
       "         2.56142608e-04, 8.14913437e-06, 2.03822328e-05, 6.26300152e-06,\n",
       "         5.90053446e-07, 3.92889451e-05, 9.10571107e-05, 3.64288026e-05,\n",
       "         4.84024895e-06, 3.58280765e-08, 5.31472142e-06, 9.99345124e-01,\n",
       "         1.98931666e-05]],\n",
       "\n",
       "       [[1.04876665e-06, 1.64558747e-04, 5.59524665e-07, 2.47252132e-07,\n",
       "         2.56142608e-04, 8.14913437e-06, 2.03822328e-05, 6.26300152e-06,\n",
       "         5.90053446e-07, 3.92889451e-05, 9.10571107e-05, 3.64288026e-05,\n",
       "         4.84024895e-06, 3.58280765e-08, 5.31472142e-06, 9.99345124e-01,\n",
       "         1.98931666e-05]],\n",
       "\n",
       "       [[1.04876665e-06, 1.64558747e-04, 5.59524665e-07, 2.47252132e-07,\n",
       "         2.56142608e-04, 8.14913437e-06, 2.03822328e-05, 6.26300152e-06,\n",
       "         5.90053446e-07, 3.92889451e-05, 9.10571107e-05, 3.64288026e-05,\n",
       "         4.84024895e-06, 3.58280765e-08, 5.31472142e-06, 9.99345124e-01,\n",
       "         1.98931666e-05]],\n",
       "\n",
       "       [[1.04876665e-06, 1.64558747e-04, 5.59524665e-07, 2.47252132e-07,\n",
       "         2.56142608e-04, 8.14913437e-06, 2.03822328e-05, 6.26300152e-06,\n",
       "         5.90053446e-07, 3.92889451e-05, 9.10571107e-05, 3.64288026e-05,\n",
       "         4.84024895e-06, 3.58280765e-08, 5.31472142e-06, 9.99345124e-01,\n",
       "         1.98931666e-05]],\n",
       "\n",
       "       [[1.04876665e-06, 1.64558747e-04, 5.59524665e-07, 2.47252132e-07,\n",
       "         2.56142608e-04, 8.14913437e-06, 2.03822328e-05, 6.26300152e-06,\n",
       "         5.90053446e-07, 3.92889451e-05, 9.10571107e-05, 3.64288026e-05,\n",
       "         4.84024895e-06, 3.58280765e-08, 5.31472142e-06, 9.99345124e-01,\n",
       "         1.98931666e-05]],\n",
       "\n",
       "       [[1.04876665e-06, 1.64558747e-04, 5.59524665e-07, 2.47252132e-07,\n",
       "         2.56142608e-04, 8.14913437e-06, 2.03822328e-05, 6.26300152e-06,\n",
       "         5.90053446e-07, 3.92889451e-05, 9.10571107e-05, 3.64288026e-05,\n",
       "         4.84024895e-06, 3.58280765e-08, 5.31472142e-06, 9.99345124e-01,\n",
       "         1.98931666e-05]],\n",
       "\n",
       "       [[1.04876665e-06, 1.64558747e-04, 5.59524665e-07, 2.47252132e-07,\n",
       "         2.56142608e-04, 8.14913437e-06, 2.03822328e-05, 6.26300152e-06,\n",
       "         5.90053446e-07, 3.92889451e-05, 9.10571107e-05, 3.64288026e-05,\n",
       "         4.84024895e-06, 3.58280765e-08, 5.31472142e-06, 9.99345124e-01,\n",
       "         1.98931666e-05]],\n",
       "\n",
       "       [[1.04876665e-06, 1.64558747e-04, 5.59524665e-07, 2.47252132e-07,\n",
       "         2.56142608e-04, 8.14913437e-06, 2.03822328e-05, 6.26300152e-06,\n",
       "         5.90053446e-07, 3.92889451e-05, 9.10571107e-05, 3.64288026e-05,\n",
       "         4.84024895e-06, 3.58280765e-08, 5.31472142e-06, 9.99345124e-01,\n",
       "         1.98931666e-05]],\n",
       "\n",
       "       [[1.04876665e-06, 1.64558747e-04, 5.59524665e-07, 2.47252132e-07,\n",
       "         2.56142608e-04, 8.14913437e-06, 2.03822328e-05, 6.26300152e-06,\n",
       "         5.90053446e-07, 3.92889451e-05, 9.10571107e-05, 3.64288026e-05,\n",
       "         4.84024895e-06, 3.58280765e-08, 5.31472142e-06, 9.99345124e-01,\n",
       "         1.98931666e-05]],\n",
       "\n",
       "       [[1.04876665e-06, 1.64558747e-04, 5.59524665e-07, 2.47252132e-07,\n",
       "         2.56142608e-04, 8.14913437e-06, 2.03822328e-05, 6.26300152e-06,\n",
       "         5.90053446e-07, 3.92889451e-05, 9.10571107e-05, 3.64288026e-05,\n",
       "         4.84024895e-06, 3.58280765e-08, 5.31472142e-06, 9.99345124e-01,\n",
       "         1.98931666e-05]],\n",
       "\n",
       "       [[1.04876665e-06, 1.64558747e-04, 5.59524665e-07, 2.47252132e-07,\n",
       "         2.56142608e-04, 8.14913437e-06, 2.03822328e-05, 6.26300152e-06,\n",
       "         5.90053446e-07, 3.92889451e-05, 9.10571107e-05, 3.64288026e-05,\n",
       "         4.84024895e-06, 3.58280765e-08, 5.31472142e-06, 9.99345124e-01,\n",
       "         1.98931666e-05]],\n",
       "\n",
       "       [[1.04876665e-06, 1.64558747e-04, 5.59524665e-07, 2.47252132e-07,\n",
       "         2.56142608e-04, 8.14913437e-06, 2.03822328e-05, 6.26300152e-06,\n",
       "         5.90053446e-07, 3.92889451e-05, 9.10571107e-05, 3.64288026e-05,\n",
       "         4.84024895e-06, 3.58280765e-08, 5.31472142e-06, 9.99345124e-01,\n",
       "         1.98931666e-05]]], dtype=float32)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_load.predict(X_te[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
