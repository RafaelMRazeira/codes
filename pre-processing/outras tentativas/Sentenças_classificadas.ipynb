{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![purple-divider](https://user-images.githubusercontent.com/7065401/52071927-c1cd7100-2562-11e9-908a-dde91ba14e59.png)\n",
    "<!-- ![green-divider](https://user-images.githubusercontent.com/7065401/52071924-c003ad80-2562-11e9-8297-1c6595f8a7ff.png) -->\n",
    "### Import our libraries and reading the dataset\n",
    "\n",
    "<!-- ![green-divider](https://user-images.githubusercontent.com/7065401/52071924-c003ad80-2562-11e9-8297-1c6595f8a7ff.png) -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "\n",
    "# sp_data is a pandas dataframe of our data\n",
    "sp_data = pd.read_json(\n",
    "    '/media/rafael/D/2020 RAFAEL/Faculdade/ICs/IC Direito/data/sp_shinx.json', lines=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![green-divider](https://user-images.githubusercontent.com/7065401/52071924-c003ad80-2562-11e9-8297-1c6595f8a7ff.png)\n",
    "### writing the regex for filter the sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @Classifiyng the sentences and not sentences via REGEX\n",
    "\n",
    "# Transform the pandas Data.frame to a series for initial interting spot\n",
    "Sp_Series = pd.Series(sp_data['Conteúdo'])\n",
    "# r_procedente = r\"(?i)(.(JULGO PROCEDENTE|JULGO TOTALMENTE PROCEDENTE).*((art\\.?|artigo).(269|487).))\"\n",
    "r_procedente = r\"(?i)(.JULGO PROCEDENTE.[^EM PARTE]|.JULGO TOTALMENTE PROCEDENTE.)\"\n",
    "r_em_parte = r\"(?i)(.JULGO PROCEDENTE EM PARTE.|.JULGO PARCIALMENTE PROCEDENTE.)\"\n",
    "r_improcedente = r\"(?i)(.JULGO IMPROCEDENTE.|.JULGO TOTALMENTE IMPROCEDENTE.)\"\n",
    "r_extinto_sem_merito = r\"(?i)(.JULGO EXTINTO.*sem.(julgamento|resolução).de.mérito.)\"\n",
    "r_homologado = r\"(?i)(.hom(o|ó)logo o acordo.)\"\n",
    "r_indeferimento_inicial = r\"(?i)(.(art\\.?|artigo) 284.)\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![green-divider](https://user-images.githubusercontent.com/7065401/52071924-c003ad80-2562-11e9-8297-1c6595f8a7ff.png)\n",
    "### Filtering the senteces and transform then into pandas.Series Object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rafael/.local/lib/python3.6/site-packages/pandas/core/strings.py:1843: UserWarning: This pattern has match groups. To actually get the groups, use str.extract.\n",
      "  return func(self, *args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "index_sentencas_procedentes = Sp_Series.str.contains(r_procedente)\n",
    "index_sentencas_procedentes = index_sentencas_procedentes.to_numpy()\n",
    "sentencas_procedentes = Sp_Series[index_sentencas_procedentes]\n",
    "\n",
    "index_sentencas_parc_proc = Sp_Series.str.contains(r_em_parte)\n",
    "index_sentencas_parc_proc = index_sentencas_parc_proc.to_numpy()\n",
    "sentencas_parc_procedentes = Sp_Series[index_sentencas_parc_proc]\n",
    "\n",
    "index_sentencas_improc = Sp_Series.str.contains(r_improcedente)\n",
    "index_sentencas_improc = index_sentencas_improc.to_numpy()\n",
    "sentencas_improcedentes = Sp_Series[index_sentencas_improc]\n",
    "\n",
    "index_sentencas_extinto_s_merito = Sp_Series.str.contains(r_extinto_sem_merito)\n",
    "index_sentencas_extinto_s_merito = index_sentencas_extinto_s_merito.to_numpy()\n",
    "sentencas_extintas_s_merito = Sp_Series[index_sentencas_extinto_s_merito]\n",
    "\n",
    "index_sentencas_homologado = Sp_Series.str.contains(r_homologado)\n",
    "index_sentencas_homologado = index_sentencas_homologado.to_numpy()\n",
    "sentencas_homologadas = Sp_Series[index_sentencas_homologado]\n",
    "\n",
    "index_sentencas_indeferimento = Sp_Series.str.contains(r_indeferimento_inicial)\n",
    "index_sentencas_indeferimento = index_sentencas_indeferimento.to_numpy()\n",
    "sentencas_indeferidas = Sp_Series[index_sentencas_indeferimento]\n",
    "\n",
    "# sentencas_procedentes, sentencas_parc_procedentes, sentencas_improcedentes, sentencas_extintas_s_merito, sentencas_homologadas, sentencas_indeferidas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![green-divider](https://user-images.githubusercontent.com/7065401/52071924-c003ad80-2562-11e9-8297-1c6595f8a7ff.png)\n",
    "### Filtering the senteces which appeared in more than one classify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = set(sentencas_procedentes.index)\n",
    "b = set(sentencas_parc_procedentes.index)\n",
    "c = set(sentencas_improcedentes.index)\n",
    "d = set(sentencas_extintas_s_merito.index)\n",
    "e = set(sentencas_homologadas.index)\n",
    "f = set(sentencas_indeferidas.index)\n",
    "\n",
    "processos_procedentes_e_parc_procedentes = a.intersection(b)\n",
    "processos_procedentes_e_improcedente = a.intersection(c)\n",
    "processos_procedentes_e_extintas_s_merito = a.intersection(d)\n",
    "processos_procedentes_e_homologadas = a.intersection(e)\n",
    "processos_Parc_procedentes_e_improcedentes = b.intersection(c)\n",
    "processos_Parc_procedentes_e_extintas_s_merito = b.intersection(d)\n",
    "processos_Parc_procedentes_e_homologadas = b.intersection(f)\n",
    "processos_Improcedentes_e_extintas_s_merito = c.intersection(d)\n",
    "processos_Improcedentes_e_homologadas = c.intersection(e)\n",
    "processos_extintas_s_merito_e_indeferidas = d.intersection(f)\n",
    "\n",
    "tudo = processos_procedentes_e_parc_procedentes.union(\n",
    "    processos_procedentes_e_improcedente)\n",
    "tudo = tudo.union(processos_procedentes_e_extintas_s_merito)\n",
    "tudo = tudo.union(processos_procedentes_e_homologadas)\n",
    "tudo = tudo.union(processos_Parc_procedentes_e_improcedentes)\n",
    "tudo = tudo.union(processos_Parc_procedentes_e_extintas_s_merito)\n",
    "tudo = tudo.union(processos_Parc_procedentes_e_homologadas)\n",
    "tudo = tudo.union(processos_Improcedentes_e_extintas_s_merito)\n",
    "tudo = tudo.union(processos_Improcedentes_e_homologadas)\n",
    "tudo = tudo.union(processos_extintas_s_merito_e_indeferidas)\n",
    "\n",
    "# Save in CSV file for future if we need\n",
    "# Sp_Series[list(tudo)].to_csv('todos_as_sentenças_complexas.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![green-divider](https://user-images.githubusercontent.com/7065401/52071924-c003ad80-2562-11e9-8297-1c6595f8a7ff.png)\n",
    "### Remove those sentences explain above from the original data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        Processo 0001543-25.2013.8.26.0344 (034.42.013...\n",
       "1        Processo 0042265-38.2012.8.26.0053 - Mandado d...\n",
       "2        Processo 1000405-68.2015.8.26.0236 - Procedime...\n",
       "3        Processo 0000276-03.2017.8.26.0627 (processo p...\n",
       "4        Processo 0007240-12.2012.8.26.0037 (apensado a...\n",
       "                               ...                        \n",
       "99995    Processo 1012114-60.2014.8.26.0002 - Interdiçã...\n",
       "99996    Processo 1000332-38.2013.8.26.0278 - Procedime...\n",
       "99997    Processo 4005073-95.2013.8.26.0302 - Ação Civi...\n",
       "99998    Processo 0011585-32.2011.8.26.0562 (562.01.201...\n",
       "99999    Processo 0079412-54.2012.8.26.0100 - Execução ...\n",
       "Name: Conteúdo, Length: 99903, dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Sp_Series_N_complexas = Sp_Series.drop(list(tudo))\n",
    "Sp_Series_N_complexas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![green-divider](https://user-images.githubusercontent.com/7065401/52071924-c003ad80-2562-11e9-8297-1c6595f8a7ff.png)\n",
    "### Append all this Classified sentences to a .JSON file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_sentencas_procedentes = Sp_Series_N_complexas.str.contains(r_procedente)\n",
    "index_sentencas_procedentes = index_sentencas_procedentes.to_numpy()\n",
    "sentencas_procedentes = Sp_Series_N_complexas[index_sentencas_procedentes]\n",
    "\n",
    "index_sentencas_parc_proc = Sp_Series_N_complexas.str.contains(r_em_parte)\n",
    "index_sentencas_parc_proc = index_sentencas_parc_proc.to_numpy()\n",
    "sentencas_parc_procedentes = Sp_Series_N_complexas[index_sentencas_parc_proc]\n",
    "\n",
    "index_sentencas_improc = Sp_Series_N_complexas.str.contains(r_improcedente)\n",
    "index_sentencas_improc = index_sentencas_improc.to_numpy()\n",
    "sentencas_improcedentes = Sp_Series_N_complexas[index_sentencas_improc]\n",
    "\n",
    "index_sentencas_extinto_s_merito = Sp_Series_N_complexas.str.contains(\n",
    "    r_extinto_sem_merito)\n",
    "index_sentencas_extinto_s_merito = index_sentencas_extinto_s_merito.to_numpy()\n",
    "sentencas_extintas_s_merito = Sp_Series_N_complexas[index_sentencas_extinto_s_merito]\n",
    "\n",
    "index_sentencas_homologado = Sp_Series_N_complexas.str.contains(r_homologado)\n",
    "index_sentencas_homologado = index_sentencas_homologado.to_numpy()\n",
    "sentencas_homologadas = Sp_Series_N_complexas[index_sentencas_homologado]\n",
    "\n",
    "index_sentencas_indeferimento = Sp_Series_N_complexas.str.contains(\n",
    "    r_indeferimento_inicial)\n",
    "index_sentencas_indeferimento = index_sentencas_indeferimento.to_numpy()\n",
    "sentencas_indeferidas = Sp_Series_N_complexas[index_sentencas_indeferimento]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentencas_proce_dt = pd.DataFrame(sentencas_procedentes)\n",
    "sentencas_proce_dt['classificacao'] = 'PROCEDENTE'\n",
    "sentencas_proce_dt['numero'] = sentencas_proce_dt.index\n",
    "\n",
    "sentencas_parc_procedentes_dt = pd.DataFrame(sentencas_parc_procedentes)\n",
    "sentencas_parc_procedentes_dt['classificacao'] = 'PARCIALMENTE PROCEDENTE'\n",
    "sentencas_parc_procedentes_dt['numero'] = sentencas_parc_procedentes_dt.index\n",
    "\n",
    "sentencas_improcedentes_dt = pd.DataFrame(sentencas_improcedentes)\n",
    "sentencas_improcedentes_dt['classificacao'] = 'IMPROCEDENTE'\n",
    "sentencas_improcedentes_dt['numero'] = sentencas_improcedentes_dt.index\n",
    "\n",
    "sentencas_extintas_s_merito_dt = pd.DataFrame(sentencas_extintas_s_merito)\n",
    "sentencas_extintas_s_merito_dt['classificacao'] = 'EXTINTO SEM MÉRITO'\n",
    "sentencas_extintas_s_merito_dt['numero'] = sentencas_extintas_s_merito_dt.index\n",
    "\n",
    "sentencas_homologadas_dt = pd.DataFrame(sentencas_homologadas)\n",
    "sentencas_homologadas_dt['classificacao'] = 'HOMOLOGADAS'\n",
    "sentencas_homologadas_dt['numero'] = sentencas_homologadas_dt.index\n",
    "\n",
    "sentencas_indeferidas_dt = pd.DataFrame(sentencas_indeferidas)\n",
    "sentencas_indeferidas_dt['classificacao'] = 'INDEFERIDAS'\n",
    "sentencas_indeferidas_dt['numero'] = sentencas_indeferidas_dt.index\n",
    "\n",
    "dt_total = sentencas_proce_dt.append(sentencas_parc_procedentes_dt)\n",
    "dt_total = dt_total.append(sentencas_improcedentes_dt)\n",
    "dt_total = dt_total.append(sentencas_extintas_s_merito_dt)\n",
    "dt_total = dt_total.append(sentencas_homologadas_dt)\n",
    "dt_total = dt_total.append(sentencas_indeferidas_dt)\n",
    "\n",
    "a, index, counts = np.unique(dt_total.index, return_counts = True, return_index = True)\n",
    "\n",
    "dt_total.drop(dt_total.index[index[counts > 1]]).to_json('Todas_sentencas_Classificadas.json', force_ascii=False, orient='index')\n",
    "# counts\n",
    "# dt_total.index != dt_total.index[counts]\n",
    "\n",
    "# dt_total.to_json('teste.json', force_ascii=False, orient='index')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
